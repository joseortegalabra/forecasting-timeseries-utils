{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b0627d-60d7-412f-97c7-c84037bb2815",
   "metadata": {},
   "source": [
    "## LGBM - ENTRENAR UN ÚNICO MODELO - FORECAST POR RECURSIVIDAD NIXTLA\n",
    "## GENERAR MÁS VARIABLES EXÓGENAS\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "- contador cuántos días faltan para un feriado\n",
    "- contador cuántos días han pasado de un feriado\n",
    "\n",
    "\n",
    "OBS IMPORTANTE: LA SEPARACIÓN DE TRAIN Y TEST SE HACE CASI AL FINAL. PORQUE CREAR VARIABLES EXÓGENAS SE PUEDE HACER UNA VEZ Y LUEGO SEPARAR, ADEMÁS CREAR VARIABLES BASADAS EN LAG NECESITA QUE EL TEST TOME ALGUNOS LAGS DE TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d272a152-d153-4891-a1eb-5d92f3b7ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root path:  /Users/joseortega/Documents/GitHub/forecasting-m5-dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set path root of repo\n",
    "actual_path = os.path.abspath(os.getcwd())\n",
    "list_root_path = actual_path.split('/')[:-1]\n",
    "root_path = '/'.join(list_root_path)\n",
    "os.chdir(root_path)\n",
    "print('root path: ', root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb0fd5c-b1da-49df-b52f-bf98579afc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from scipy.stats import skew, kurtosis, variation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import mlforecast\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from utilsforecast.feature_engineering import fourier\n",
    "\n",
    "\n",
    "# documentacion lag transform\n",
    "# https://nixtlaverse.nixtla.io/coreforecast/lag_transforms\n",
    "from mlforecast.lag_transforms import RollingMean, SeasonalRollingMean\n",
    "from mlforecast.lag_transforms import RollingStd, RollingMin, RollingMax\n",
    "from mlforecast.lag_transforms import ExpandingMean, ExpandingStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6ecbe2-36a9-4717-87d4-481803b8fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f096a526-5999-4213-80bc-b7f00855dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f2d6cc-9306-4366-a223-631062e383eb",
   "metadata": {},
   "source": [
    "### 1. Definir parámetros\n",
    "- Recordar que las fechas se muestran como \"d_xx\", \"date\" y \"week\"\n",
    "- Las fechas \"d_xx\" se pueden omitir ya que cruzando con la tabla calendario se puede obtener el \"date\"\n",
    "- LAS FECHAS DE INICIO Y FIN DE TEST, SE OBTIENEN DEL NOTEBOOK \"generar_data_test\". Se define primero test y luego contar hacia atrás cuántos días mostrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6474741b-3cab-40b4-85b5-1959130852f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "date_start_test = '2016-04-25'\n",
    "date_end_test = '2016-05-22'\n",
    "\n",
    "#week_start_test = 11613\n",
    "#week_end_test = 11617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b24da6d-f300-46bc-b9e6-6ba68b6cb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN. EN TRAIN SE DEFINEN LA ÚLTIMA FECHA DE ENTENAMIENTO Y CUÁNTOS DÍAS HACIA ATRÁS SE USARAN PARA EL INICIO DE TRAIN\n",
    "date_end_train = '2016-04-24'\n",
    "days_used_to_train = 400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76870eb3-c341-4a90-a1a4-e009c5cac35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a08ae23-06ee-491a-a2ec-0c5295da9303",
   "metadata": {},
   "source": [
    "### 2. Obtener fecha de incio de entrenamiento\n",
    "Desde fecha de fin y días hacia atrás a considerar para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05aed859-7fb3-4780-b8d8-92562e5ed353",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_end_train_datetime = pd.to_datetime(date_end_train)\n",
    "date_start_train_datetime = date_end_train_datetime - pd.Timedelta(days=days_used_to_train)\n",
    "date_start_train = date_start_train_datetime.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6e994a7-9ff6-45b6-91e6-fb6eadc308a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-03-21'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print fecha de incio train\n",
    "date_start_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ba4c7-cc40-48a2-99cc-84978cca8d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdfb0f-95a6-4725-8fab-9189d512b223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6597f1e6-a442-446e-bd6d-f7f587f41dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7555d48-bb7e-46b2-bfef-5465cb874fa3",
   "metadata": {},
   "source": [
    "### 2. Read raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665f9961-ecd6-4043-89e0-d75409701df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data = 'data/data_input_dtype/'\n",
    "\n",
    "df_calender = pd.read_pickle(folder_data + 'calendar.pkl')\n",
    "df_prices = pd.read_pickle(folder_data + 'sell_prices.pkl')\n",
    "df_sales = pd.read_pickle(folder_data + 'sales_train_evaluation.pkl')\n",
    "df_sample_output = pd.read_pickle(folder_data + 'sample_submission.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318feed0-f336-47b3-865f-bc7b83ff1e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_2</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_3</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  wm_yr_wk    d event_name_1 event_type_1 event_name_2  \\\n",
       "0 2011-01-29     11101  d_1          nan          nan          nan   \n",
       "1 2011-01-30     11101  d_2          nan          nan          nan   \n",
       "2 2011-01-31     11101  d_3          nan          nan          nan   \n",
       "\n",
       "  event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          nan        0        0        0  \n",
       "1          nan        0        0        0  \n",
       "2          nan        0        0        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca17841-e5e5-4b01-8e01-16999a023045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58\n",
       "2     CA_1  HOBBIES_1_001     11327        8.26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293282db-ef0a-4601-9b52-06a1eb67ab81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA  0.0  0.0  0.0  0.0  ...     2.0     4.0     0.0     0.0     0.0   \n",
       "1       CA  0.0  0.0  0.0  0.0  ...     0.0     1.0     2.0     1.0     1.0   \n",
       "2       CA  0.0  0.0  0.0  0.0  ...     1.0     0.0     2.0     0.0     0.0   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0     0.0     3.0     3.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     2.0     3.0     0.0     1.0  \n",
       "\n",
       "[3 rows x 1947 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d2081-8242-49e3-ada1-612e9a923ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae97960-afb2-4568-9d2d-3d6599684eab",
   "metadata": {},
   "source": [
    "### 3. Transformar df_sales a formato compatible con modelos de forecast timeseries y que permita hacer merge con df_calender y df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e298948-face-4348-935b-0bee9a197ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar las ventas a formato que necesita nixtla. FORMATO: (ID_SERIE, TIMESTAMP, VALUE)\n",
    "data = df_sales.melt(\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='d',\n",
    "    value_name='y'\n",
    ")\n",
    "\n",
    "# correguir id de la serie. Eliminar \"evaluation\" para tener nombres más cortos\n",
    "data['id'] = data['id'].str.rsplit('_', n=1).str[0].astype('category')\n",
    "\n",
    "# cambiar tipo de dato a tipo category\n",
    "# data['d'] = data['d'].astype(df_calender.d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86d085e-561f-4e77-b53b-aa6ad439a1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        item_id    dept_id   cat_id store_id state_id  \\\n",
       "0  HOBBIES_1_001_CA_1  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "1  HOBBIES_1_002_CA_1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "2  HOBBIES_1_003_CA_1  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "3  HOBBIES_1_004_CA_1  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "4  HOBBIES_1_005_CA_1  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "\n",
       "     d    y  \n",
       "0  d_1  0.0  \n",
       "1  d_1  0.0  \n",
       "2  d_1  0.0  \n",
       "3  d_1  0.0  \n",
       "4  d_1  0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0d507-8afc-4fd3-b40b-09afa3a1181b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf1959-15a2-460f-8a56-b6e8359e71bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdc723f2-df1b-4cd3-b6ce-13eb8d16ba9c",
   "metadata": {},
   "source": [
    "### 4. Merge data con df_calender y df_prices.\n",
    "Tener un solo df con todas las variables exógenas. Luego, hacer algun procesamiento adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d428f6-3297-45b5-b6e7-a227c71cac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge con df calender Tener df con la data de info de feriados, eventos, etc\n",
    "data = data.merge(df_calender, on=['d'])\n",
    "\n",
    "# Merge con df prices. Variable exógenas. Precios cada id. Agregación semanal\n",
    "data = data.merge(df_prices, on=['store_id', 'item_id', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38775e72-06fa-44e8-80ed-3d7654fba580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar nombre columna de fechas \"date\" a \"ds\" para replicar formato usado por otras librerias\n",
    "data = data.rename(columns = {'date':'ds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3830ae0b-ec60-4ae7-a03b-6b67bee1e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REORDENAR LAS COLUMNAS DE FORMA ALEATORIA \n",
    "\n",
    "# - DIFERENCIA CON RESPECTO A BASELINE. EN ESTA PRUEBA NO SE REORDENAN \n",
    "\n",
    "# data = data.sample(frac=1.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f88feeb-0cc5-4704-ae37-67728141886e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        item_id    dept_id   cat_id store_id state_id  \\\n",
       "0  HOBBIES_1_008_CA_1  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "1  HOBBIES_1_009_CA_1  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "2  HOBBIES_1_010_CA_1  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "\n",
       "     d     y         ds  wm_yr_wk event_name_1 event_type_1 event_name_2  \\\n",
       "0  d_1  12.0 2011-01-29     11101          nan          nan          nan   \n",
       "1  d_1   2.0 2011-01-29     11101          nan          nan          nan   \n",
       "2  d_1   0.0 2011-01-29     11101          nan          nan          nan   \n",
       "\n",
       "  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0          nan        0        0        0        0.46  \n",
       "1          nan        0        0        0        1.56  \n",
       "2          nan        0        0        0        3.17  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88891d42-55c1-4856-b232-752d96b36c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfc3811-5494-4821-851a-edfc25853360",
   "metadata": {},
   "source": [
    "### 5. Ordenar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d390bf7-f8ae-411c-89c5-ea35f65c17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenar data de la forma [Serie, timestamp]. Ver en el dataframe los datos de cada serie ordenados por fechas\n",
    "data = data.sort_values(['id', 'ds'])\n",
    "data = data.reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc06863-b811-4871-b964-cb482fcb224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      item_id  dept_id cat_id store_id state_id    d    y  \\\n",
       "0  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_1  3.0   \n",
       "1  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_2  0.0   \n",
       "2  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_3  0.0   \n",
       "\n",
       "          ds  wm_yr_wk event_name_1 event_type_1 event_name_2 event_type_2  \\\n",
       "0 2011-01-29     11101          nan          nan          nan          nan   \n",
       "1 2011-01-30     11101          nan          nan          nan          nan   \n",
       "2 2011-01-31     11101          nan          nan          nan          nan   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0        0        0        0         2.0  \n",
       "1        0        0        0         2.0  \n",
       "2        0        0        0         2.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03774fc-50c7-4d43-a4e4-e9eb05f622d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b1f881-2292-4133-938b-da8c1c1c4096",
   "metadata": {},
   "source": [
    "### 6. Generar variables exógenas\n",
    "Generar listado variables exógenas. Luego de tener un df todas las variables exógenas, separar en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a4ed279-3dbe-4cad-9598-fe62fb92ddeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      item_id  dept_id cat_id store_id state_id    d    y  \\\n",
       "0  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_1  3.0   \n",
       "1  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_2  0.0   \n",
       "2  FOODS_1_001_CA_1  FOODS_1_001  FOODS_1  FOODS     CA_1       CA  d_3  0.0   \n",
       "\n",
       "          ds  wm_yr_wk event_name_1 event_type_1 event_name_2 event_type_2  \\\n",
       "0 2011-01-29     11101          nan          nan          nan          nan   \n",
       "1 2011-01-30     11101          nan          nan          nan          nan   \n",
       "2 2011-01-31     11101          nan          nan          nan          nan   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  sell_price  \n",
       "0        0        0        0         2.0  \n",
       "1        0        0        0         2.0  \n",
       "2        0        0        0         2.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce13d75b-938b-4faa-9045-6581658dc3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### crear variable exógena indicador de la serie\n",
    "def create_exogena_id_serie(df):\n",
    "    \"\"\" crear variable exógena indicador de la serie \"\"\"\n",
    "    df['id_serie'] = pd.factorize(df['id'])[0]\n",
    "    return df\n",
    "    \n",
    "data = create_exogena_id_serie(df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13bd4784-4c81-41c4-8c82-9c12a76f7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### transformar NULL de columnas eventos a un valor NO NULL para ser aceptado por modelos. Se transforma a \"nan\"\n",
    "# LO MÁS LÓGICO ES TRANSFORMAR A NÚMEROS, PERO LOS MODELOS DE ÁRBOLES PUEDEN MANEJAR LAS VARIABLES STRING, ASI QUE NO ES NECESARIO\n",
    "\n",
    "# data calender ya viene de esta forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1ffd888-ab44-4c69-a3b6-54371f042e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### agregar variable exógena binaria - 1: es un dia feriado por calendario // 0: no lo es\n",
    "def create_exogena_binaria_event_calender(df):\n",
    "    \"\"\" agregar variable exógena binaria 1: es un día de evento por calendario // 0: no lo es \"\"\"\n",
    "    \n",
    "    # obs en una de las transformaciones de los datos, los NaN se dejaron como string 'nan'\n",
    "    # si al menos una de las columnas 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2' tiene valor, ES UN EVENTO\n",
    "    df['event'] = df[['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']].replace('nan', np.NaN).notnull().any(axis=1).astype(int)\n",
    "\n",
    "    return df\n",
    "    \n",
    "data = create_exogena_binaria_event_calender(df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501076af-e035-4a74-8b4d-165ccad7bbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9f6b07a-eccb-4cee-a07a-fa43025ffca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSTRAR LOS EVENTOS DE CADA AÑO\n",
    "# data[data['event'] == 1].groupby(['ds'])[['ds', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'event']].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8c542-3d68-4439-b532-41ea1bd2319a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8280e59d-b8d4-40f2-9c5e-60c5f50a7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "### agregar variabler exógena contador de todos los días antes y después de algún evento. Que diga 1 días del evento, 2 días antes, etc\n",
    "def create_exogena_contador_dias_antes_y_despues_event(df):\n",
    "    \"\"\" \n",
    "    Agregar variabler exógena contador de todos los días antes y después de algún evento. Que diga 1 días del evento, 2 días antes, etc\n",
    "    - Se cuantan los días que faltan para el próximo evento\n",
    "    - Se cuentan los días que han pasado desde el último evento\n",
    "    \"\"\"\n",
    "    df_ds_oneserie = df[['ds', 'event']].drop_duplicates()\n",
    "    df_ds_oneserie.sort_values(by = 'ds', ascending = True, inplace = True)\n",
    "\n",
    "    holidays_aux = df_ds_oneserie['ds'].loc[df_ds_oneserie['event'] == 1].tolist()\n",
    "    holidays_aux = pd.to_datetime(holidays_aux, dayfirst=True)\n",
    "    df_ds_oneserie_hd = pd.DataFrame({'date1':holidays_aux})\n",
    "\n",
    "    out = pd.merge_asof(df_ds_oneserie, df_ds_oneserie_hd, left_on='ds', right_on='date1', direction='forward')\n",
    "    out = pd.merge_asof(out, df_ds_oneserie_hd, left_on='ds', right_on='date1')\n",
    "\n",
    "    out['days_last_holiday'] = out['ds'].sub(out.pop('date1_y')).dt.days\n",
    "    out['days_next_holiday'] = out.pop('date1_x').sub(out['ds']).dt.days\n",
    "\n",
    "    df = pd.merge(df, out, on=['ds', 'event'], how='left')\n",
    "    df['days_last_holiday'] = df['days_last_holiday'].fillna(0)\n",
    "    df['days_next_holiday'] = df['days_next_holiday'].fillna(0) # rellenar nulos con cero. DE QUÉ OTRA FORMA SE PODRIAN RELLENAR LOS NULOS\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "data = create_exogena_contador_dias_antes_y_despues_event(df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a38a1f5f-ce50-45ef-a979-921b7bfefd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### crear indicadores si es día de semana, si es fin de semana, si es sabado, si es domingo\n",
    "def create_exogena_indicadores_dias_semana(df):\n",
    "    \"\"\" crear indicadores si es día de semana, si es fin de semana, si es sabado, si es domingo \"\"\"\n",
    "    \n",
    "    # si es dia de semana\n",
    "    df['week_day'] = (df['ds'].dt.dayofweek <= 4).astype(int)\n",
    "\n",
    "    # si es sabado\n",
    "    #df['sabado_day'] = (df['ds'].dt.dayofweek == 5).astype(int)\n",
    "\n",
    "    # si es domingo\n",
    "    #df['domingo_day'] = (df['ds'].dt.dayofweek == 6).astype(int)\n",
    "\n",
    "    # indicador si es la primera, segunda, tercera, cuarta semana del mes\n",
    "    df['indice_semana_en_mes'] = (df['ds'].dt.day - 1) // 7 + 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "data = create_exogena_indicadores_dias_semana(df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743a28f-1183-44d2-9200-d4681882cd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2397a7ac-7749-4245-bf8a-04fa29d9baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calcular variacion en precios para cada serie con respecto a semanas previas\n",
    "\n",
    "def create_exogena_variacion_prices_past_weeks(df, df_prices, list_delay):\n",
    "    \"\"\"\n",
    "    Tomar df con precios por semana y calcular variación en el precio con respecto a semanas previas.\n",
    "    Se puede hacer varias comparación con respecto a varias semanas previas\n",
    "    Luego, se agrega la variación semanal en los precios\n",
    "    \n",
    "    IMPORTANTE: AL GENERAR VARIACIÓN SE VAN A GENERAR NULOS. REVISARLO EN PROX PASOS. puede NO SER UN PROBLEMA, si se toman\n",
    "    X observaciones atrás sin considerar toda la data para entrenar\n",
    "    \n",
    "    Args\n",
    "        df (DataFrame): Dataframe con la data\n",
    "        df_prices (DataFrame): DataFrame que tiene solo los precios (estructura del df original con los precios)\n",
    "        list_delay (list): Lista con semanas a calcular delay de precios por cada serie. 1: vs semana anterior, 4: vs 4 semanas atras\n",
    "    Return\n",
    "        df (DataFrame): DataFrame con la data, agregada las variables exógenas relacionadas a delay con precios\n",
    "    \"\"\"\n",
    "    \n",
    "    # crear variable auxiliar con precios\n",
    "    df_aux_prices = df_prices.copy()\n",
    "\n",
    "\n",
    "    # recorrer cada item_id y calcular la variacion de precio con respecto a un periodo anterior\n",
    "    list_unique_item_id = df_aux_prices['item_id'].unique()\n",
    "    for unique_item_id in list_unique_item_id:\n",
    "    \n",
    "        # calcular mask para item id que cuadre. \n",
    "        # PODER FILTRAR DATAFRAME SOLO POR EL ITEM ID QUE INTERESA SIN TENER QUE CREAR DF AUXLIAR\n",
    "        mask_unique_item_id = df_aux_prices['item_id'] == unique_item_id\n",
    "\n",
    "        \n",
    "        for delay in list_delay:\n",
    "            \n",
    "            # llevar precios del pasado al futuro para poder hacer precio(t) - precio(t-1)\n",
    "            df_aux_prices.loc[mask_unique_item_id, 'sell_price_lagged'] = df_aux_prices.loc[mask_unique_item_id, 'sell_price'].shift(delay)\n",
    "            \n",
    "            # calcular delta de precio con respecto a variación de un periodo anterior\n",
    "            df_aux_prices.loc[mask_unique_item_id, f'delta_price_{delay}'] = df_aux_prices.loc[mask_unique_item_id, 'sell_price'] - df_aux_prices.loc[mask_unique_item_id, 'sell_price_lagged']\n",
    "\n",
    "    \n",
    "    # Merge variacion semanal precios con data\n",
    "    df_aux_prices = df_aux_prices.drop(columns = ['sell_price', 'sell_price_lagged'])\n",
    "    df = df.merge(df_aux_prices, on=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5006f75-9d74-47ca-a66c-816247c385f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46881677, 24)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8320d81-2512-489c-ad4f-5c99caea56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calcular variacion en precios para cada serie con respecto a semanas previas\n",
    "data = create_exogena_variacion_prices_past_weeks(df = data, \n",
    "                                                  df_prices = df_prices, \n",
    "                                                  list_delay = [1, 4, 8, 12]\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43fc6f06-d9db-4ec9-be67-33780d1d5923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46881677, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3b2be-16f6-42d8-8e6d-d9b6b24f4d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499747f2-dff4-467e-8dae-0c8ff2ea158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3bcbb2-5797-4d85-b999-fd55ffb3c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e5d6dbd-aaf4-4ba8-ad2a-d82404986c0b",
   "metadata": {},
   "source": [
    "### 7. Eliminar columnas no utiizada\n",
    "Eliminar columnas no utilizadas en la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f7219c3-a23e-4622-8c81-a6882263fa9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46881677, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a20b38-f3b3-475a-9610-d998eab7f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PASO FINAL - ELIMINAR COLUMNAS NO UTILIZADA\n",
    "# eliminar columnas\n",
    "data = data.drop(columns=['d', 'wm_yr_wk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "708ce10f-6297-4fcd-8cc5-852d5281310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46881677, 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154e947-3a14-4560-9017-be6ab4724cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e228a5-2ac0-43ab-aa4e-cd57df589fde",
   "metadata": {},
   "source": [
    "### 8. Filtrar data train y test\n",
    "- Filtrar data train de acuerdo a rango de fechas utilizados para train\n",
    "- Existe una función que consulta métrica (obtiene datos reales de test) y calcula métrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63888cc2-748b-4e13-b951-f7fb62136917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train:  (12177819, 26)\n",
      "shape test:  (853720, 26)\n"
     ]
    }
   ],
   "source": [
    "################## separar data train y test de acuerdo a rango de fechas definidas ##################\n",
    "mask_train = (data['ds'] >= date_start_train) & (data['ds'] <= date_end_train)\n",
    "data_train = data[mask_train]\n",
    "\n",
    "mask_test = (data['ds'] >= date_start_test) & (data['ds'] <= date_end_test)\n",
    "data_test = data[mask_test]\n",
    "\n",
    "print('shape train: ', data_train.shape)\n",
    "print('shape test: ', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f11465a-3feb-444f-b20b-15bce8ed54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## agregar variable exógena transformada de fourier ##################\n",
    "\n",
    "def create_exogena_transformada_fourier(df_train, df_test, diferencia_dias_horizon_fcst):\n",
    "    \"\"\" agregar variable exógena transformada de fourier. Se utiliza clase nixtla que recibe data train y retorna data train y data test/future \"\"\"\n",
    "\n",
    "    # renombrar columna \"id\" al nombre \"unique_id\". nixlta necesita que tenga ese nombre\n",
    "    df_train = df_train.rename(columns = {'id': 'unique_id'})\n",
    "    df_test = df_test.rename(columns = {'id': 'unique_id'})\n",
    "\n",
    "    \n",
    "    transformed_fourier_df_train, future_fourier_df = fourier(df_train, freq='D', season_length = 7, k = 3, h = diferencia_dias_horizon_fcst)\n",
    "\n",
    "    df_train = transformed_fourier_df_train # funcion retorna el dataframe de train agregadas las columnas de las transformada\n",
    "    df_test = pd.merge(df_test, future_fourier_df, on=['unique_id', 'ds'], how='inner') # funcion retorna solo la transformada para los datos de test - unir\n",
    "\n",
    "\n",
    "    # regresar a nombre id de columnas original\n",
    "    df_train = df_train.rename(columns = {'unique_id': 'id'})\n",
    "    df_test = df_test.rename(columns = {'unique_id': 'id'})\n",
    "\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "data_train, data_test = create_exogena_transformada_fourier(df_train = data_train, \n",
    "                                                            df_test = data_test,\n",
    "                                                            diferencia_dias_horizon_fcst = 28\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "350b31bd-3e2a-401a-a3a1-230c95b92ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'y', 'ds',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'id_serie', 'event',\n",
       "       'days_last_holiday', 'days_next_holiday', 'week_day',\n",
       "       'indice_semana_en_mes', 'delta_price_1', 'delta_price_4',\n",
       "       'delta_price_8', 'delta_price_12', 'sin1_7', 'sin2_7', 'sin3_7',\n",
       "       'cos1_7', 'cos2_7', 'cos3_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c3486-eb61-467f-b0ab-019a498edc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## separar data train y test de acuerdo a rango de fechas definidas ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec88ad-75ab-485c-9c24-c4b69c284853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b9c2e-a3ed-4378-a3fa-d2aa8b6b7a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16525c5-bddc-41b1-bfab-0b40de9220d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf092604-7061-40cc-b63d-ad2c300bb581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3c225-a28e-48d8-a74e-8bec018b1d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba601542-7c71-4e8d-9f40-0f879f3811ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
